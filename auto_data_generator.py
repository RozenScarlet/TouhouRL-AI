# auto_data_generator.py
"""
åŸºäºä½ç½®æµ‹è¯•.pyçš„æ¸¸æˆå¯¹è±¡æ£€æµ‹åŠŸèƒ½ï¼Œè‡ªåŠ¨ç”ŸæˆYOLOv8è®­ç»ƒæ•°æ®
åˆ©ç”¨ç°æœ‰çš„GameObjectDetectorç±»è¿›è¡Œå®æ—¶æ¸¸æˆæˆªå›¾å’Œæ ‡æ³¨

æ”¹è¿›åŠŸèƒ½ï¼š
- æ•°æ®è´¨é‡æ§åˆ¶å’ŒéªŒè¯
- å¤šæ ·æ€§ä¿è¯æœºåˆ¶
- è‡ªé€‚åº”é‡‡æ ·ç‡
- æ•°æ®æ¸…æ´—å’Œåå¤„ç†
- å¢å¼ºçš„å¯è§†åŒ–éªŒè¯
"""

import sys
import os
from pathlib import Path
import cv2
import numpy as np
import time
import keyboard
import mss
import subprocess
import json
import win32gui
from typing import Dict, List, Tuple
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„ï¼Œä»¥ä¾¿å¯¼å…¥ä½ç½®æµ‹è¯•.py
project_root = Path(__file__).parent.parent
sys.path.append(str(project_root))

# å¯¼å…¥ä½ç½®æµ‹è¯•.pyä¸­çš„æ£€æµ‹å™¨
try:
    from ä½ç½®æµ‹è¯• import GameObjectDetector as BaseGameObjectDetector
except ImportError:
    print("é”™è¯¯ï¼šæ— æ³•å¯¼å…¥ä½ç½®æµ‹è¯•.pyä¸­çš„GameObjectDetectorç±»")
    print("è¯·ç¡®ä¿ä½ç½®æµ‹è¯•.pyæ–‡ä»¶åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸­")
    sys.exit(1)


class EnhancedGameObjectDetector(BaseGameObjectDetector):
    """å¢å¼ºç‰ˆæ¸¸æˆå¯¹è±¡æ£€æµ‹å™¨ - è‡ªæœºå›ºå®š6x6ï¼Œå­å¼¹åŠ¨æ€å¤§å°"""

    def find_hitbox_center_improved(self, img, player_bbox):
        """æ”¹è¿›çš„åˆ¤å®šç‚¹æ£€æµ‹ - æ›´å‡†ç¡®åœ°å®šä½è‡ªæœºä¸­å¿ƒ"""
        x, y, w, h = player_bbox

        # é¦–å…ˆå°è¯•åŸå§‹çš„ç™½è‰²åˆ¤å®šç‚¹æ£€æµ‹
        original_center = self.find_hitbox_center(img, player_bbox)

        # æ£€æŸ¥åŸå§‹æ£€æµ‹æ˜¯å¦åªæ˜¯å›é€€åˆ°äº†å‡ ä½•ä¸­å¿ƒ
        geometric_center = (x + w // 2, y + h // 2)

        # å¦‚æœåŸå§‹æ£€æµ‹è¿”å›çš„å°±æ˜¯å‡ ä½•ä¸­å¿ƒï¼Œè¯´æ˜æ²¡æ‰¾åˆ°ç™½è‰²åˆ¤å®šç‚¹
        if original_center == geometric_center:
            # ä½¿ç”¨æ”¹è¿›çš„æ–¹æ³•ï¼šåˆ†æè‡ªæœºç²¾çµçš„è§†è§‰é‡å¿ƒ
            return self.find_visual_center(img, player_bbox)
        else:
            # æ‰¾åˆ°äº†ç™½è‰²åˆ¤å®šç‚¹ï¼Œç›´æ¥ä½¿ç”¨
            return original_center

    def find_visual_center(self, img, player_bbox):
        """é€šè¿‡åˆ†æè‡ªæœºç²¾çµçš„è§†è§‰ç‰¹å¾æ‰¾åˆ°æ›´å‡†ç¡®çš„ä¸­å¿ƒç‚¹"""
        x, y, w, h = player_bbox

        # ç®€åŒ–æ–¹æ¡ˆï¼šç›´æ¥ä½¿ç”¨å‡ ä½•ä¸­å¿ƒï¼Œä½†è¿›è¡Œåˆç†çš„åç§»è°ƒæ•´
        # æ ¹æ®ä¸œæ–¹æ¸¸æˆçš„ç‰¹ç‚¹ï¼Œåˆ¤å®šç‚¹é€šå¸¸åœ¨è‡ªæœºç²¾çµçš„è§†è§‰ä¸­å¿ƒ
        # è€Œä¸æ˜¯æ£€æµ‹åˆ°çš„çº¢è‰²åŒºåŸŸçš„å‡ ä½•ä¸­å¿ƒ

        center_x = x + w // 2
        center_y = y + h // 2

        # æ ¹æ®åé¦ˆè°ƒæ•´åç§»é‡ï¼š
        # 1. å‡å°‘å·¦åç§»ï¼ˆä¹‹å‰åç§»å¤ªå¤šäº†ï¼‰
        # 2. ç¨å¾®å‘ä¸Šåç§»ï¼ˆå› ä¸ºåˆ¤å®šç‚¹é€šå¸¸åœ¨ç²¾çµä¸­å¿ƒåä¸Šï¼‰
        adjusted_x = center_x   # å‘å·¦åç§»1/16å®½åº¦ï¼ˆå‡å°‘åç§»ï¼‰
        adjusted_y = center_y - h // 8   # å‘ä¸Šåç§»1/8é«˜åº¦

        # ç¡®ä¿è°ƒæ•´åçš„ç‚¹ä»åœ¨è‡ªæœºåŒºåŸŸå†…
        adjusted_x = max(x, min(x + w, adjusted_x))
        adjusted_y = max(y, min(y + h, adjusted_y))

        return (adjusted_x, adjusted_y)

    def detect_bullets_with_dynamic_size(self, img, player_bbox=None):
        """æ£€æµ‹å­å¼¹ä½ç½®ï¼Œå¹¶è¿”å›åŸºäºç™½è‰²åŒºåŸŸå¤§å°çš„åŠ¨æ€å°ºå¯¸ - æ”¹è¿›ç‰ˆå¤„ç†è¿ç»­å­å¼¹"""
        bullets = []

        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) if len(img.shape) == 3 else img

        # å¦‚æœæœ‰è‡ªæœºä½ç½®ï¼Œåˆ›å»ºä¸€ä¸ªæ©ç æ¥æ’é™¤è‡ªæœºåŒºåŸŸ
        mask = np.ones(gray.shape, dtype=np.uint8) * 255
        if player_bbox is not None:
            x, y, w, h = player_bbox
            # åœ¨è‡ªæœºä¸­å¿ƒåŒºåŸŸåˆ›å»ºä¸€ä¸ªå°çš„æ’é™¤åŒºåŸŸ
            center_x = x + w // 2
            center_y = y + h // 2
            exclusion_radius = min(w, h) // 3
            cv2.circle(mask, (center_x, center_y), exclusion_radius, 0, -1)

        # ä½¿ç”¨äº®åº¦èŒƒå›´æ£€æµ‹å­å¼¹
        min_brightness = 230
        max_brightness = 255

        # åˆ›å»ºäº®åº¦èŒƒå›´æ©ç 
        brightness_mask = cv2.inRange(gray, min_brightness, max_brightness)

        # åº”ç”¨è‡ªæœºæ’é™¤æ©ç 
        brightness_mask = cv2.bitwise_and(brightness_mask, mask)

        contours, _ = cv2.findContours(brightness_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        for cnt in contours:
            area = cv2.contourArea(cnt)
            if 3 < area < 2000:  # å¢åŠ æœ€å¤§é¢ç§¯ä»¥å¤„ç†è¿ç»­å­å¼¹
                x, y, w, h = cv2.boundingRect(cnt)

                # åˆ¤æ–­æ˜¯å¦ä¸ºè¿ç»­å­å¼¹ï¼ˆé•¿æ¡å½¢çŠ¶ï¼‰
                aspect_ratio = max(w, h) / min(w, h) if min(w, h) > 0 else 1

                if aspect_ratio > 3:  # é•¿å®½æ¯”å¤§äº3ï¼Œå¯èƒ½æ˜¯è¿ç»­å­å¼¹
                    # å¤„ç†è¿ç»­å­å¼¹ï¼šæ²¿é•¿è½´æ–¹å‘åˆ†å‰²
                    bullets.extend(self.split_continuous_bullets(cnt, x, y, w, h, brightness_mask))
                else:
                    # å¤„ç†å•ä¸ªå­å¼¹
                    M = cv2.moments(cnt)
                    if M["m00"] != 0:
                        cx = int(M["m10"] / M["m00"])
                        cy = int(M["m01"] / M["m00"])

                        # æ ¹æ®ç™½è‰²åŒºåŸŸçš„å®é™…å¤§å°è®¡ç®—æ ‡æ³¨æ¡†å¤§å°
                        bullet_size = max(min(w, h), 4)  # è‡³å°‘4åƒç´ 
                        bullet_size = min(bullet_size, 16)  # æœ€å¤š16åƒç´ 

                        # æå–ä¸­å¿ƒæ­£æ–¹å½¢åŒºåŸŸè¿›è¡ŒéªŒè¯
                        half_size = bullet_size // 2
                        center_x1 = max(0, cx - half_size)
                        center_y1 = max(0, cy - half_size)
                        center_x2 = min(gray.shape[1], cx + half_size)
                        center_y2 = min(gray.shape[0], cy + half_size)

                        center_region = brightness_mask[center_y1:center_y2, center_x1:center_x2]

                        if center_region.size > 0:
                            white_pixel_ratio = np.sum(center_region > 0) / center_region.size

                            if white_pixel_ratio > 0.3:
                                # é¿å…é‡å¤æ£€æµ‹
                                is_duplicate = False
                                for existing in bullets:
                                    if abs(existing['center'][0] - cx) < 5 and abs(existing['center'][1] - cy) < 5:
                                        is_duplicate = True
                                        break

                                if not is_duplicate:
                                    # è·å–è¯¥ç‚¹çš„å®é™…äº®åº¦å€¼
                                    actual_brightness = gray[cy, cx] if 0 <= cy < gray.shape[0] and 0 <= cx < gray.shape[1] else 0

                                    bullets.append({
                                        'center': (cx, cy),
                                        'bbox': (x, y, w, h),
                                        'area': area,
                                        'brightness': actual_brightness,
                                        'square_size': bullet_size * 2,  # ä¿æŒå…¼å®¹æ€§
                                        'dynamic_size': bullet_size  # æ–°å¢ï¼šåŠ¨æ€è®¡ç®—çš„å¤§å°
                                    })

        return bullets

    def split_continuous_bullets(self, contour, x, y, w, h, brightness_mask):
        """åˆ†å‰²è¿ç»­å­å¼¹ä¸ºå•ä¸ªå­å¼¹"""
        bullets = []

        # ç¡®å®šæ˜¯æ°´å¹³è¿˜æ˜¯å‚ç›´æ’åˆ—
        is_horizontal = w > h

        if is_horizontal:
            # æ°´å¹³æ’åˆ—ï¼šæ²¿xè½´åˆ†å‰²
            bullet_width = min(w // max(1, w // 8), 12)  # ä¼°ç®—å•ä¸ªå­å¼¹å®½åº¦
            num_bullets = max(1, w // bullet_width)

            for i in range(num_bullets):
                bullet_x = x + i * bullet_width + bullet_width // 2
                bullet_y = y + h // 2

                # éªŒè¯è¿™ä¸ªä½ç½®ç¡®å®æœ‰ç™½è‰²åƒç´ 
                if (0 <= bullet_y < brightness_mask.shape[0] and
                    0 <= bullet_x < brightness_mask.shape[1] and
                    brightness_mask[bullet_y, bullet_x] > 0):

                    bullets.append({
                        'center': (bullet_x, bullet_y),
                        'bbox': (bullet_x - bullet_width//2, y, bullet_width, h),
                        'area': bullet_width * h,
                        'brightness': 255,
                        'square_size': bullet_width * 2,
                        'dynamic_size': max(4, min(bullet_width, 12))
                    })
        else:
            # å‚ç›´æ’åˆ—ï¼šæ²¿yè½´åˆ†å‰²
            bullet_height = min(h // max(1, h // 8), 12)  # ä¼°ç®—å•ä¸ªå­å¼¹é«˜åº¦
            num_bullets = max(1, h // bullet_height)

            for i in range(num_bullets):
                bullet_x = x + w // 2
                bullet_y = y + i * bullet_height + bullet_height // 2

                # éªŒè¯è¿™ä¸ªä½ç½®ç¡®å®æœ‰ç™½è‰²åƒç´ 
                if (0 <= bullet_y < brightness_mask.shape[0] and
                    0 <= bullet_x < brightness_mask.shape[1] and
                    brightness_mask[bullet_y, bullet_x] > 0):

                    bullets.append({
                        'center': (bullet_x, bullet_y),
                        'bbox': (x, bullet_y - bullet_height//2, w, bullet_height),
                        'area': w * bullet_height,
                        'brightness': 255,
                        'square_size': bullet_height * 2,
                        'dynamic_size': max(4, min(bullet_height, 12))
                    })

        return bullets

class OptimizedGameCapture:
    """æ¸¸æˆçª—å£æ•è·ç±» - å‚è€ƒtouhou_rl.pyçš„å®ç°"""

    def __init__(self, window_name="æ¶æ›½å³ æºå«¿ä¸‚ä¹£ the Embodiment of Scarlet Devil", game_path="D:\\Games\\th06\\vpatch.exe"):
        self.sct = mss.mss()
        self.window_name = window_name
        self.game_path = game_path
        self.window_rect = None

        # ä¸œæ–¹çº¢é­”ä¹¡åˆ†è¾¨ç‡
        self.game_width = 640
        self.game_height = 480

        # å¼¹å¹•åŒºåŸŸ
        self.gameplay_x, self.gameplay_y = 32, 16
        self.gameplay_width, self.gameplay_height = 384, 448

    def start_game_and_find_window(self):
        """å¯åŠ¨æ¸¸æˆå¹¶æŸ¥æ‰¾çª—å£"""
        print(f"ğŸ® æ­£åœ¨å¯åŠ¨æ¸¸æˆ: {self.game_path}")

        # å¯åŠ¨æ¸¸æˆ
        try:
            subprocess.Popen(f'"{self.game_path}"', shell=True)
            print("æ¸¸æˆå¯åŠ¨å‘½ä»¤å·²æ‰§è¡Œ")
        except Exception as e:
            print(f"å¯åŠ¨æ¸¸æˆå¤±è´¥: {e}")
            return False

        # ç­‰å¾…æ¸¸æˆçª—å£å‡ºç°
        print("ç­‰å¾…æ¸¸æˆçª—å£å‡ºç°...")
        for i in range(10):  # æœ€å¤šç­‰å¾…10ç§’
            time.sleep(1)
            if self.set_window_by_name():
                print("âœ… æ¸¸æˆçª—å£å·²æ‰¾åˆ°å¹¶è®¾ç½®ä¸ºå‰å°")
                return True
            print(f"ç­‰å¾…ä¸­... ({i+1}/10)")

        print("âŒ æ¸¸æˆçª—å£æœªæ‰¾åˆ°")
        return False

    def set_window_by_name(self):
        """æŸ¥æ‰¾æ¸¸æˆçª—å£ - å‚è€ƒtouhou_rl.pyçš„å®ç°"""
        def callback(hwnd, _):
            try:
                if win32gui.IsWindowVisible(hwnd) and win32gui.GetWindowText(hwnd) == self.window_name:
                    rect = win32gui.GetWindowRect(hwnd)
                    client = win32gui.GetClientRect(hwnd)
                    border_w = ((rect[2] - rect[0]) - client[2]) // 2
                    title_h = (rect[3] - rect[1]) - client[3] - border_w
                    self.window_rect = (
                        rect[0] + border_w,
                        rect[1] + title_h,
                        client[2],
                        client[3]
                    )
                    # è®¾ç½®çª—å£ä¸ºå‰å°
                    win32gui.SetForegroundWindow(hwnd)
                    return False
            except:
                pass
            return True

        try:
            win32gui.EnumWindows(callback, None)
            if self.window_rect:
                print(f"æ‰¾åˆ°æ¸¸æˆçª—å£: {self.window_name}")
                return True
            else:
                return False
        except Exception as e:
            print(f"æŸ¥æ‰¾çª—å£å¤±è´¥: {e}")
            return False

    def capture_full_window(self):
        """æˆªå–å®Œæ•´æ¸¸æˆçª—å£ - å‚è€ƒtouhou_rl.pyçš„å®ç°"""
        if not self.window_rect:
            return np.zeros((self.game_height, self.game_width, 4), dtype=np.uint8)

        left, top, client_width, client_height = self.window_rect
        monitor = {
            "left": left,
            "top": top,
            "width": self.game_width,
            "height": self.game_height
        }

        try:
            full_img = np.array(self.sct.grab(monitor))
            return full_img
        except Exception as e:
            print(f"æˆªå›¾å¤±è´¥: {e}")
            return None

    def capture_gameplay_area(self):
        """æˆªå–å¼¹å¹•åŒºåŸŸ"""
        full_img = self.capture_full_window()
        if full_img is None:
            return None

        # æå–å¼¹å¹•åŒºåŸŸ
        gameplay_img = full_img[
            self.gameplay_y : self.gameplay_y + self.gameplay_height,
            self.gameplay_x : self.gameplay_x + self.gameplay_width
        ]

        # è½¬æ¢ä¸ºBGRæ ¼å¼ï¼ˆOpenCVæ ‡å‡†ï¼‰
        if gameplay_img.shape[2] == 4:  # BGRA
            gameplay_img = cv2.cvtColor(gameplay_img, cv2.COLOR_BGRA2BGR)

        return gameplay_img

class PreprocessingWorkflow:
    """é¢„å¤„ç†å·¥ä½œæµ - æ‰‹åŠ¨æˆªå›¾å’Œæ‰¹é‡åå¤„ç†"""

    def __init__(self, preprocessing_dir: str = "preprocessing"):
        self.preprocessing_dir = Path(preprocessing_dir)
        self.preprocessing_dir.mkdir(exist_ok=True)

        # åˆ›å»ºå­ç›®å½•
        self.raw_images_dir = self.preprocessing_dir / "raw_images"
        self.visualizations_dir = self.preprocessing_dir / "visualizations"
        self.annotations_dir = self.preprocessing_dir / "annotations"

        self.raw_images_dir.mkdir(exist_ok=True)
        self.visualizations_dir.mkdir(exist_ok=True)
        self.annotations_dir.mkdir(exist_ok=True)

        # åˆå§‹åŒ–æ£€æµ‹å™¨å’Œæ•è·å™¨
        self.detector = EnhancedGameObjectDetector()
        self.capture = OptimizedGameCapture()

        # é”®ç›˜ç›‘å¬çŠ¶æ€
        self.is_listening = False
        self.capture_count = 0

        print(f"é¢„å¤„ç†å·¥ä½œæµåˆå§‹åŒ–å®Œæˆ")
        print(f"é¢„å¤„ç†ç›®å½•: {self.preprocessing_dir}")
        print(f"åŸå§‹å›¾åƒ: {self.raw_images_dir}")
        print(f"å¯è§†åŒ–ç»“æœ: {self.visualizations_dir}")
        print(f"æ ‡æ³¨æ•°æ®: {self.annotations_dir}")

    def start_manual_capture(self):
        """å¼€å§‹æ‰‹åŠ¨æˆªå›¾æ¨¡å¼ - æŒ‰Ré”®æˆªå›¾"""
        print("\nğŸ® æ‰‹åŠ¨æˆªå›¾æ¨¡å¼å·²å¯åŠ¨")
        print("æŒ‰ 'R' é”®æˆªå–å½“å‰æ¸¸æˆç”»é¢")
        print("æŒ‰ 'Q' é”®é€€å‡ºæˆªå›¾æ¨¡å¼")
        print("=" * 50)

        self.is_listening = True
        self.capture_count = 0

        try:
            while self.is_listening:
                if keyboard.is_pressed('r'):
                    self.capture_single_frame()
                    time.sleep(0.5)  # é˜²æ­¢é‡å¤è§¦å‘

                if keyboard.is_pressed('q'):
                    print("\né€€å‡ºæ‰‹åŠ¨æˆªå›¾æ¨¡å¼")
                    self.is_listening = False
                    break

                time.sleep(0.1)  # å‡å°‘CPUå ç”¨

        except KeyboardInterrupt:
            print("\næ‰‹åŠ¨æˆªå›¾æ¨¡å¼è¢«ä¸­æ–­")
            self.is_listening = False

    def capture_single_frame(self):
        """æˆªå–å•å¸§æ¸¸æˆç”»é¢"""
        img = self.capture.capture_gameplay_area()
        if img is None:
            print("âŒ æˆªå›¾å¤±è´¥")
            return False

        # ç”Ÿæˆæ–‡ä»¶å
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")[:-3]
        filename = f"capture_{timestamp}_{self.capture_count:04d}.jpg"

        # ä¿å­˜åŸå§‹å›¾åƒ
        img_path = self.raw_images_dir / filename
        success = cv2.imwrite(str(img_path), img)

        if success:
            self.capture_count += 1
            print(f"âœ… æˆªå›¾ #{self.capture_count}: {filename}")
            return True
        else:
            print(f"âŒ ä¿å­˜å¤±è´¥: {filename}")
            return False

    def process_single_image(self, img_path: Path) -> dict | None:
        """å¤„ç†å•å¼ å›¾åƒï¼Œè¿”å›æ£€æµ‹ç»“æœ"""
        img = cv2.imread(str(img_path))
        if img is None:
            return None

        # æ£€æµ‹æ¸¸æˆå¯¹è±¡
        player_detections = self.detector.detect_player_position(img)
        player_bbox = None
        if player_detections:
            player_bbox = player_detections[0]['bbox']
            # ä½¿ç”¨æ”¹è¿›çš„åˆ¤å®šç‚¹æ£€æµ‹
            improved_center = self.detector.find_hitbox_center_improved(img, player_bbox)
            # æ›´æ–°æ£€æµ‹ç»“æœ
            for player in player_detections:
                player['center'] = improved_center  # ä½¿ç”¨æ”¹è¿›çš„ä¸­å¿ƒç‚¹
                player['hitbox_size'] = 4  # å›ºå®š4x4åƒç´ 

        bullet_detections = self.detector.detect_bullets_with_dynamic_size(img, player_bbox)

        # ç»„ç»‡æ£€æµ‹ç»“æœ
        detections = {
            'player': player_detections,
            'bullets': bullet_detections,
            'image_shape': img.shape,
            'filename': img_path.name
        }

        return detections

    def create_visualization(self, img_path: Path, detections: dict) -> Path | None:
        """åˆ›å»ºå¯è§†åŒ–æ•ˆæœå›¾ - æ˜¾ç¤ºåˆ¤å®šç‚¹å’Œå¯¹åº”çš„æ ‡æ³¨æ¡†"""
        img = cv2.imread(str(img_path))
        if img is None:
            return None

        result_img = img.copy()
        h, w = img.shape[:2]

        # ç»˜åˆ¶è‡ªæœºåˆ¤å®šç‚¹å’Œæ ‡æ³¨æ¡†
        for player in detections.get('player', []):
            cx, cy = player['center']

            # è‡ªæœºå›ºå®šä½¿ç”¨4x4åƒç´ 
            hitbox_size = 4
            half_size = hitbox_size // 2

            # æ ‡æ³¨æ¡†åæ ‡
            x1 = max(0, cx - half_size)
            y1 = max(0, cy - half_size)
            x2 = min(w, cx + half_size)
            y2 = min(h, cy + half_size)

            # ç»˜åˆ¶æ ‡æ³¨æ¡†ï¼ˆç»¿è‰²çŸ©å½¢ï¼‰
            cv2.rectangle(result_img, (x1, y1), (x2, y2), (0, 255, 0), 2)

            # ç»˜åˆ¶åˆ¤å®šç‚¹ï¼ˆç™½è‰²åœ†åœˆå¸¦ç»¿è‰²è¾¹æ¡†ï¼‰
            cv2.circle(result_img, (cx, cy), 3, (255, 255, 255), -1)
            cv2.circle(result_img, (cx, cy), 4, (0, 255, 0), 2)

            # ç»˜åˆ¶åå­—æ ‡è®°
            cv2.line(result_img, (cx - 8, cy), (cx + 8, cy), (0, 255, 0), 1)
            cv2.line(result_img, (cx, cy - 8), (cx, cy + 8), (0, 255, 0), 1)

            # æ·»åŠ æ ‡ç­¾
            cv2.putText(result_img, 'Player', (cx + 10, cy - 10),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 255, 0), 1)

            # æ˜¾ç¤ºæ ‡æ³¨æ¡†å°ºå¯¸ä¿¡æ¯
            box_info = f"{hitbox_size}x{hitbox_size}"
            cv2.putText(result_img, box_info, (x1, y1 - 5),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.3, (0, 255, 0), 1)

        # ç»˜åˆ¶å­å¼¹åˆ¤å®šç‚¹å’Œæ ‡æ³¨æ¡†
        for bullet in detections.get('bullets', []):
            cx, cy = bullet['center']

            # ä½¿ç”¨åŠ¨æ€è®¡ç®—çš„å­å¼¹å¤§å°
            hitbox_size = bullet.get('dynamic_size', 4)  # ä½¿ç”¨åŠ¨æ€å¤§å°ï¼Œé»˜è®¤4
            half_size = hitbox_size // 2

            # æ ‡æ³¨æ¡†åæ ‡
            x1 = max(0, cx - half_size)
            y1 = max(0, cy - half_size)
            x2 = min(w, cx + half_size)
            y2 = min(h, cy + half_size)

            # ç»˜åˆ¶æ ‡æ³¨æ¡†ï¼ˆçº¢è‰²çŸ©å½¢ï¼‰
            cv2.rectangle(result_img, (x1, y1), (x2, y2), (0, 0, 255), 1)

            # ç»˜åˆ¶å­å¼¹åˆ¤å®šç‚¹ï¼ˆçº¢è‰²å°åœ†ç‚¹ï¼‰
            cv2.circle(result_img, (cx, cy), 2, (0, 0, 255), -1)
            cv2.circle(result_img, (cx, cy), 3, (255, 255, 255), 1)

            # æ˜¾ç¤ºå­å¼¹å¤§å°ä¿¡æ¯
            bullet_info = f"{hitbox_size}x{hitbox_size}"
            cv2.putText(result_img, bullet_info, (x1, y1 - 5),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.25, (0, 0, 255), 1)

        # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
        player_count = len(detections.get('player', []))
        bullet_count = len(detections.get('bullets', []))
        info_text = f"Players: {player_count} | Bullets: {bullet_count}"
        cv2.putText(result_img, info_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)

        # æ·»åŠ æ ‡æ³¨æ¡†è¯´æ˜
        legend_y = 50
        cv2.putText(result_img, "Green Box: Player Hitbox (4x4 fixed)", (10, legend_y),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)
        cv2.putText(result_img, "Red Box: Bullet Hitbox (dynamic size)", (10, legend_y + 20),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)

        # æ·»åŠ æ–‡ä»¶å
        cv2.putText(result_img, detections['filename'], (10, img.shape[0] - 10),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)

        # ä¿å­˜å¯è§†åŒ–ç»“æœ
        vis_filename = f"vis_{detections['filename']}"
        vis_path = self.visualizations_dir / vis_filename
        cv2.imwrite(str(vis_path), result_img)

        return vis_path

    def save_annotation_json(self, detections: dict) -> Path:
        """ä¿å­˜JSONæ ¼å¼çš„æ ‡æ³¨æ–‡ä»¶"""
        annotation_data = {
            'filename': detections['filename'],
            'image_shape': {
                'height': detections['image_shape'][0],
                'width': detections['image_shape'][1],
                'channels': detections['image_shape'][2]
            },
            'detections': {
                'player': [],
                'bullets': []
            },
            'statistics': {
                'player_count': len(detections.get('player', [])),
                'bullet_count': len(detections.get('bullets', [])),
                'processed_time': datetime.now().isoformat()
            }
        }

        # å¤„ç†è‡ªæœºæ£€æµ‹ç»“æœ
        for player in detections.get('player', []):
            player_data = {
                'center': player['center'],
                'bbox': player.get('bbox', []),
                'confidence': player.get('confidence', 1.0)
            }
            annotation_data['detections']['player'].append(player_data)

        # å¤„ç†å­å¼¹æ£€æµ‹ç»“æœ
        for bullet in detections.get('bullets', []):
            bullet_data = {
                'center': bullet['center'],
                'square_size': bullet.get('square_size', 4),
                'dynamic_size': bullet.get('dynamic_size', 4),  # ä¿å­˜åŠ¨æ€å¤§å°
                'confidence': bullet.get('confidence', 1.0)
            }
            annotation_data['detections']['bullets'].append(bullet_data)

        # ä¿å­˜JSONæ–‡ä»¶
        json_filename = f"ann_{detections['filename'].replace('.jpg', '.json')}"
        json_path = self.annotations_dir / json_filename

        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(annotation_data, f, indent=2, ensure_ascii=False)

        return json_path

    def batch_process_images(self):
        """æ‰¹é‡å¤„ç†é¢„å¤„ç†æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰å›¾åƒ"""
        image_files = list(self.raw_images_dir.glob("*.jpg"))

        if not image_files:
            print("âŒ é¢„å¤„ç†æ–‡ä»¶å¤¹ä¸­æ²¡æœ‰æ‰¾åˆ°å›¾åƒæ–‡ä»¶")
            return

        print(f"\nğŸ”„ å¼€å§‹æ‰¹é‡å¤„ç† {len(image_files)} å¼ å›¾åƒ...")
        print("=" * 50)

        processed_count = 0
        failed_count = 0

        for i, img_path in enumerate(image_files, 1):
            print(f"å¤„ç†è¿›åº¦: {i}/{len(image_files)} - {img_path.name}")

            try:
                # æ£€æµ‹å¯¹è±¡
                detections = self.process_single_image(img_path)
                if detections is None:
                    print(f"  âŒ å›¾åƒè¯»å–å¤±è´¥")
                    failed_count += 1
                    continue

                # åˆ›å»ºå¯è§†åŒ–
                vis_path = self.create_visualization(img_path, detections)
                if vis_path:
                    print(f"  âœ… å¯è§†åŒ–: {vis_path.name}")

                # ä¿å­˜JSONæ ‡æ³¨
                json_path = self.save_annotation_json(detections)
                print(f"  âœ… æ ‡æ³¨: {json_path.name}")

                # æ˜¾ç¤ºæ£€æµ‹ç»Ÿè®¡
                player_count = len(detections.get('player', []))
                bullet_count = len(detections.get('bullets', []))
                print(f"  ğŸ“Š æ£€æµ‹ç»“æœ: {player_count} è‡ªæœº, {bullet_count} å­å¼¹")

                processed_count += 1

            except Exception as e:
                print(f"  âŒ å¤„ç†å¤±è´¥: {e}")
                failed_count += 1

        print("\n" + "=" * 50)
        print(f"ğŸ‰ æ‰¹é‡å¤„ç†å®Œæˆ!")
        print(f"æˆåŠŸå¤„ç†: {processed_count} å¼ ")
        print(f"å¤„ç†å¤±è´¥: {failed_count} å¼ ")
        print(f"å¯è§†åŒ–æ–‡ä»¶: {self.visualizations_dir}")
        print(f"æ ‡æ³¨æ–‡ä»¶: {self.annotations_dir}")



class YOLODataGenerator:
    """YOLOè®­ç»ƒæ•°æ®è‡ªåŠ¨ç”Ÿæˆå™¨ - ä¸“æ³¨äºåˆ¤å®šç‚¹æ£€æµ‹"""

    def __init__(self, output_dir: str = "yolo/data"):
        self.output_dir = Path(output_dir)
        # åªéœ€è¦è®­ç»ƒé›†ï¼Œä¸éœ€è¦éªŒè¯é›†
        self.images_dir = self.output_dir / "images" / "train"
        self.labels_dir = self.output_dir / "labels" / "train"

        # åˆ›å»ºè¾“å‡ºç›®å½•
        self.images_dir.mkdir(parents=True, exist_ok=True)
        self.labels_dir.mkdir(parents=True, exist_ok=True)

        # åˆå§‹åŒ–æ£€æµ‹å™¨å’Œæ•è·å™¨
        self.detector = EnhancedGameObjectDetector()
        self.capture = OptimizedGameCapture()

        # ç±»åˆ«æ˜ å°„ - åªæ£€æµ‹åˆ¤å®šç‚¹
        self.class_mapping = {
            'player_hitbox': 0,    # è‡ªæœºåˆ¤å®šç‚¹
            'bullet_center': 1     # å­å¼¹åˆ¤å®šç‚¹
        }

        # åˆ¤å®šç‚¹å¤§å°è®¾ç½®ï¼ˆåƒç´ ï¼‰
        self.player_hitbox_size = 4    # è‡ªæœºåˆ¤å®šæ¡†å›ºå®š4x4
        self.bullet_hitbox_size = 4    # å­å¼¹åˆ¤å®šæ¡†é»˜è®¤å¤§å°ï¼ˆåŠ¨æ€è°ƒæ•´ï¼‰
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.generated_count = 0
        self.start_time = None
        
        print(f"YOLOæ•°æ®ç”Ÿæˆå™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"è¾“å‡ºç›®å½•: {self.output_dir}")
        print(f"å›¾åƒç›®å½•: {self.images_dir}")
        print(f"æ ‡ç­¾ç›®å½•: {self.labels_dir}")
    
    def convert_detections_to_yolo(self, detections: Dict, img_shape: Tuple[int, int]) -> List[str]:
        """å°†æ£€æµ‹ç»“æœè½¬æ¢ä¸ºYOLOæ ¼å¼æ ‡æ³¨ - ä¸“æ³¨äºåˆ¤å®šç‚¹"""
        h, w = img_shape[:2]
        annotations = []

        # å¤„ç†è‡ªæœºåˆ¤å®šç‚¹
        if 'player' in detections and detections['player']:
            for player_det in detections['player']:
                # è·å–åˆ¤å®šç‚¹åæ ‡ï¼ˆä½ç½®æµ‹è¯•.pyè¿”å›çš„centerå°±æ˜¯åˆ¤å®šç‚¹ï¼‰
                hitbox_x, hitbox_y = player_det['center']

                # è½¬æ¢ä¸ºYOLOæ ¼å¼ï¼ˆä»¥åˆ¤å®šç‚¹ä¸ºä¸­å¿ƒçš„å°æ¡†ï¼‰
                center_x = hitbox_x / w
                center_y = hitbox_y / h

                # åˆ¤å®šç‚¹çš„æ ‡æ³¨æ¡†å¤§å°ï¼ˆå½’ä¸€åŒ–ï¼‰
                norm_w = self.player_hitbox_size / w
                norm_h = self.player_hitbox_size / h

                # ç¡®ä¿åæ ‡åœ¨æœ‰æ•ˆèŒƒå›´å†…
                center_x = max(0, min(1, center_x))
                center_y = max(0, min(1, center_y))
                norm_w = max(0, min(1, norm_w))
                norm_h = max(0, min(1, norm_h))

                class_id = self.class_mapping['player_hitbox']
                annotations.append(f"{class_id} {center_x:.6f} {center_y:.6f} {norm_w:.6f} {norm_h:.6f}")

        # å¤„ç†å­å¼¹åˆ¤å®šç‚¹
        if 'bullets' in detections and detections['bullets']:
            for bullet in detections['bullets']:
                # è·å–å­å¼¹ä¸­å¿ƒç‚¹åæ ‡
                bullet_x, bullet_y = bullet['center']

                # è½¬æ¢ä¸ºYOLOæ ¼å¼ï¼ˆä»¥å­å¼¹ä¸­å¿ƒä¸ºåˆ¤å®šç‚¹ï¼‰
                center_x = bullet_x / w
                center_y = bullet_y / h

                # ä½¿ç”¨åŠ¨æ€è®¡ç®—çš„å­å¼¹å¤§å°
                actual_bullet_size = bullet.get('dynamic_size', self.bullet_hitbox_size)
                norm_w = actual_bullet_size / w
                norm_h = actual_bullet_size / h

                # ç¡®ä¿åæ ‡åœ¨æœ‰æ•ˆèŒƒå›´å†…
                center_x = max(0, min(1, center_x))
                center_y = max(0, min(1, center_y))
                norm_w = max(0, min(1, norm_w))
                norm_h = max(0, min(1, norm_h))

                class_id = self.class_mapping['bullet_center']
                annotations.append(f"{class_id} {center_x:.6f} {center_y:.6f} {norm_w:.6f} {norm_h:.6f}")

        return annotations
    
    def save_training_sample(self, img: np.ndarray, annotations: List[str]) -> bool:
        """ä¿å­˜è®­ç»ƒæ ·æœ¬ï¼ˆå›¾åƒå’Œæ ‡ç­¾ï¼‰"""
        if len(annotations) == 0:
            return False  # æ²¡æœ‰æ£€æµ‹åˆ°ä»»ä½•å¯¹è±¡ï¼Œè·³è¿‡
            
        # ç”Ÿæˆæ–‡ä»¶å
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")[:-3]  # ç²¾ç¡®åˆ°æ¯«ç§’
        filename = f"touhou_{timestamp}_{self.generated_count:06d}"
        
        # ä¿å­˜å›¾åƒ
        img_path = self.images_dir / f"{filename}.jpg"
        success = cv2.imwrite(str(img_path), img)
        
        if not success:
            print(f"ä¿å­˜å›¾åƒå¤±è´¥: {img_path}")
            return False
        
        # ä¿å­˜æ ‡ç­¾
        label_path = self.labels_dir / f"{filename}.txt"
        try:
            with open(label_path, 'w') as f:
                f.write('\n'.join(annotations))
        except Exception as e:
            print(f"ä¿å­˜æ ‡ç­¾å¤±è´¥: {e}")
            return False
        
        self.generated_count += 1
        return True

    def create_yolo_visualization(self, img: np.ndarray, annotations: List[str], filename: str) -> Path | None:
        """åˆ›å»ºYOLOæ ¼å¼æ ‡æ³¨çš„å¯è§†åŒ–å›¾åƒ"""
        if len(annotations) == 0:
            return None

        result_img = img.copy()
        h, w = img.shape[:2]

        # è§£æYOLOæ ‡æ³¨å¹¶ç»˜åˆ¶
        for annotation in annotations:
            parts = annotation.strip().split()
            if len(parts) != 5:
                continue

            class_id = int(parts[0])
            center_x = float(parts[1]) * w
            center_y = float(parts[2]) * h
            box_w = float(parts[3]) * w
            box_h = float(parts[4]) * h

            # è®¡ç®—è¾¹ç•Œæ¡†åæ ‡
            x1 = int(center_x - box_w / 2)
            y1 = int(center_y - box_h / 2)
            x2 = int(center_x + box_w / 2)
            y2 = int(center_y + box_h / 2)

            # æ ¹æ®ç±»åˆ«é€‰æ‹©é¢œè‰²
            if class_id == 0:  # player_hitbox
                color = (0, 255, 0)  # ç»¿è‰²
                label = "Player"
            elif class_id == 1:  # bullet_center
                color = (0, 0, 255)  # çº¢è‰²
                label = "Bullet"
            else:
                color = (255, 255, 255)  # ç™½è‰²
                label = f"Class{class_id}"

            # ç»˜åˆ¶è¾¹ç•Œæ¡†
            line_thickness = 2 if class_id == 0 else 1  # è‡ªæœºç”¨ç¨ç²—çš„çº¿
            cv2.rectangle(result_img, (x1, y1), (x2, y2), color, line_thickness)

            # ç»˜åˆ¶ä¸­å¿ƒç‚¹
            cv2.circle(result_img, (int(center_x), int(center_y)), 3, color, -1)
            cv2.circle(result_img, (int(center_x), int(center_y)), 4, (255, 255, 255), 1)

            # æ·»åŠ æ ‡ç­¾
            cv2.putText(result_img, label, (x1, y1 - 5),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.4, color, 1)

        # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
        player_count = sum(1 for ann in annotations if ann.startswith('0 '))
        bullet_count = sum(1 for ann in annotations if ann.startswith('1 '))
        info_text = f"YOLO: {player_count} Players, {bullet_count} Bullets"
        cv2.putText(result_img, info_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)

        # ä¿å­˜YOLOå¯è§†åŒ–ç»“æœ
        yolo_vis_dir = self.output_dir / "visualizations"
        yolo_vis_dir.mkdir(exist_ok=True)

        vis_filename = f"yolo_vis_{filename}.jpg"
        vis_path = yolo_vis_dir / vis_filename
        cv2.imwrite(str(vis_path), result_img)

        return vis_path

    def convert_from_preprocessing(self, preprocessing_dir: str = "preprocessing"):
        """æ ¹æ®å¯è§†åŒ–æ–‡ä»¶å¤¹ä¸­å‰©ä½™çš„æ–‡ä»¶æ¥è½¬æ¢YOLOè®­ç»ƒæ•°æ®"""
        preprocessing_path = Path(preprocessing_dir)
        raw_images_dir = preprocessing_path / "raw_images"
        annotations_dir = preprocessing_path / "annotations"
        visualizations_dir = preprocessing_path / "visualizations"

        if not visualizations_dir.exists():
            print("âŒ å¯è§†åŒ–ç›®å½•ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿è¡Œé¢„å¤„ç†å·¥ä½œæµ")
            return

        # ä»¥å¯è§†åŒ–æ–‡ä»¶ä¸ºå‡†ï¼Œè·å–ç”¨æˆ·ç­›é€‰åä¿ç•™çš„æ–‡ä»¶
        vis_files = list(visualizations_dir.glob("vis_*.jpg"))

        if not vis_files:
            print("âŒ å¯è§†åŒ–æ–‡ä»¶å¤¹ä¸­æ²¡æœ‰æ–‡ä»¶ï¼Œè¯·å…ˆå¤„ç†æˆªå›¾æˆ–æ£€æŸ¥æ˜¯å¦å·²åˆ é™¤æ‰€æœ‰æ–‡ä»¶")
            return

        print(f"\nğŸ”„ æ ¹æ®å¯è§†åŒ–æ–‡ä»¶å¤¹è½¬æ¢YOLOè®­ç»ƒæ•°æ®...")
        print(f"æ‰¾åˆ° {len(vis_files)} ä¸ªç­›é€‰åçš„å¯è§†åŒ–æ–‡ä»¶")
        print("ğŸ“‹ å°†æ ¹æ®è¿™äº›æ–‡ä»¶è½¬æ¢å¯¹åº”çš„åŸå§‹æ•°æ®")

        converted_count = 0
        missing_files = []

        for vis_file in vis_files:
            try:
                # ä»å¯è§†åŒ–æ–‡ä»¶åæå–åŸå§‹æ–‡ä»¶å
                # vis_capture_20250621_015440_937_0000.jpg -> capture_20250621_015440_937_0000.jpg
                vis_filename = vis_file.name
                if vis_filename.startswith("vis_"):
                    img_filename = vis_filename[4:]  # å»æ‰ "vis_" å‰ç¼€
                else:
                    print(f"âš ï¸ å¯è§†åŒ–æ–‡ä»¶åæ ¼å¼ä¸æ­£ç¡®: {vis_filename}")
                    continue

                # æŸ¥æ‰¾å¯¹åº”çš„åŸå§‹æ–‡ä»¶
                img_path = raw_images_dir / img_filename
                json_filename = f"ann_{img_filename.replace('.jpg', '.json')}"
                json_path = annotations_dir / json_filename

                # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
                if not img_path.exists():
                    missing_files.append(f"åŸå§‹å›¾åƒ: {img_filename}")
                    continue

                if not json_path.exists():
                    missing_files.append(f"æ ‡æ³¨æ–‡ä»¶: {json_filename}")
                    continue

                # è¯»å–JSONæ ‡æ³¨
                with open(json_path, 'r', encoding='utf-8') as f:
                    annotation_data = json.load(f)

                # è¯»å–å›¾åƒ
                img = cv2.imread(str(img_path))
                if img is None:
                    print(f"âš ï¸ æ— æ³•è¯»å–å›¾åƒ: {img_filename}")
                    continue

                # è½¬æ¢æ£€æµ‹ç»“æœæ ¼å¼
                detections = {
                    'player': annotation_data['detections']['player'],
                    'bullets': annotation_data['detections']['bullets']
                }

                # è½¬æ¢ä¸ºYOLOæ ¼å¼
                annotations = self.convert_detections_to_yolo(detections, (img.shape[0], img.shape[1]))

                # ä¿å­˜YOLOè®­ç»ƒæ ·æœ¬
                if self.save_training_sample(img, annotations):
                    converted_count += 1

                    # åˆ›å»ºYOLOå¯è§†åŒ–
                    yolo_vis_path = self.create_yolo_visualization(img, annotations, img_filename.replace('.jpg', ''))
                    print(f"âœ… è½¬æ¢å®Œæˆ: {img_filename} -> YOLOæ ·æœ¬ #{self.generated_count}")

            except Exception as e:
                print(f"âŒ è½¬æ¢å¤±è´¥ {vis_file.name}: {e}")

        # æ˜¾ç¤ºç¼ºå¤±æ–‡ä»¶ä¿¡æ¯
        if missing_files:
            print(f"\nâš ï¸ ä»¥ä¸‹æ–‡ä»¶ç¼ºå¤±ï¼Œæœªèƒ½è½¬æ¢:")
            for missing in missing_files[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
                print(f"   - {missing}")
            if len(missing_files) > 5:
                print(f"   ... è¿˜æœ‰ {len(missing_files) - 5} ä¸ªæ–‡ä»¶ç¼ºå¤±")

        print(f"\nğŸ‰ YOLOæ•°æ®è½¬æ¢å®Œæˆ!")
        print(f"æˆåŠŸè½¬æ¢: {converted_count} ä¸ªæ ·æœ¬")
        print(f"YOLOæ•°æ®ç›®å½•: {self.output_dir}")
        print(f"YOLOå¯è§†åŒ–ç›®å½•: {self.output_dir / 'visualizations'}")

        # åªæ¸…ç†å·²è½¬æ¢çš„æ–‡ä»¶ï¼Œä¿ç•™æ–‡ä»¶å¤¹ç»“æ„
        if converted_count > 0:
            try:
                # æ¸…ç†å·²è½¬æ¢çš„æ–‡ä»¶
                deleted_files = 0

                # åˆ é™¤å¯¹åº”çš„åŸå§‹å›¾åƒå’Œæ ‡æ³¨æ–‡ä»¶
                for vis_file in vis_files:
                    vis_filename = vis_file.name
                    if vis_filename.startswith("vis_"):
                        img_filename = vis_filename[4:]  # å»æ‰ "vis_" å‰ç¼€

                        # åˆ é™¤åŸå§‹å›¾åƒ
                        img_path = raw_images_dir / img_filename
                        if img_path.exists():
                            img_path.unlink()
                            deleted_files += 1

                        # åˆ é™¤æ ‡æ³¨æ–‡ä»¶
                        json_filename = f"ann_{img_filename.replace('.jpg', '.json')}"
                        json_path = annotations_dir / json_filename
                        if json_path.exists():
                            json_path.unlink()
                            deleted_files += 1

                        # åˆ é™¤å¯è§†åŒ–æ–‡ä»¶
                        vis_file.unlink()
                        deleted_files += 1

                print(f"ğŸ—‘ï¸ å·²åˆ é™¤ {deleted_files} ä¸ªå·²è½¬æ¢çš„æ–‡ä»¶")
                print(f"ğŸ“ ä¿ç•™äº†preprocessingæ–‡ä»¶å¤¹ç»“æ„")

            except Exception as e:
                print(f"âš ï¸ æ¸…ç†æ–‡ä»¶å¤±è´¥: {e}")

        # ç”Ÿæˆæ•°æ®é›†é…ç½®æ–‡ä»¶
        self.create_dataset_config()

    def create_dataset_config(self):
        """åˆ›å»ºYOLOè®­ç»ƒæ‰€éœ€çš„æ•°æ®é›†é…ç½®æ–‡ä»¶"""
        config_content = f"""# Touhou Hitbox Detection Dataset Configuration
# Generated automatically by auto_data_generator.py

path: {self.output_dir.absolute()}  # dataset root dir
train: images/train  # train images (relative to 'path')
val: images/train    # val images (same as train for now)

# Classes
nc: 2  # number of classes
names: ['player_hitbox', 'bullet_center']  # class names

# Class descriptions:
# 0: player_hitbox - è‡ªæœºåˆ¤å®šç‚¹ (4x4 pixels)
# 1: bullet_center - å­å¼¹åˆ¤å®šç‚¹ (dynamic size based on white area)
"""

        config_path = self.output_dir / "dataset.yaml"
        with open(config_path, 'w', encoding='utf-8') as f:
            f.write(config_content)

        print(f"âœ… æ•°æ®é›†é…ç½®æ–‡ä»¶å·²åˆ›å»º: {config_path}")

        # åˆ›å»ºè®­ç»ƒè„šæœ¬
        self.create_training_script()

    def create_training_script(self):
        """åˆ›å»ºYOLOè®­ç»ƒè„šæœ¬"""
        script_content = f"""#!/usr/bin/env python3
# -*- coding: utf-8 -*-
\"\"\"
ä¸œæ–¹çº¢é­”ä¹¡åˆ¤å®šç‚¹æ£€æµ‹ - YOLOè®­ç»ƒè„šæœ¬
è‡ªåŠ¨ç”Ÿæˆäº: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
\"\"\"

from ultralytics import YOLO
import torch

def main():
    print("ğŸ¯ å¼€å§‹è®­ç»ƒä¸œæ–¹çº¢é­”ä¹¡åˆ¤å®šç‚¹æ£€æµ‹æ¨¡å‹...")

    # æ£€æŸ¥GPUå¯ç”¨æ€§
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    print(f"ä½¿ç”¨è®¾å¤‡: {{device}}")

    # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
    model = YOLO('yolov8n.pt')  # ä½¿ç”¨nanoç‰ˆæœ¬ï¼Œé€Ÿåº¦å¿«

    # è®­ç»ƒå‚æ•°
    results = model.train(
        data='{self.output_dir.absolute() / "dataset.yaml"}',
        epochs=100,
        imgsz=640,
        batch=16,
        device=device,
        project='runs/detect',
        name='touhou_hitbox',
        save=True,
        save_period=10,
        val=True,
        plots=True,
        verbose=True
    )

    print("ğŸ‰ è®­ç»ƒå®Œæˆ!")
    print(f"æœ€ä½³æ¨¡å‹ä¿å­˜åœ¨: runs/detect/touhou_hitbox/weights/best.pt")

    # éªŒè¯æ¨¡å‹
    metrics = model.val()
    print(f"éªŒè¯ç»“æœ: mAP50={{metrics.box.map50:.3f}}, mAP50-95={{metrics.box.map:.3f}}")

if __name__ == "__main__":
    main()
"""

        script_path = self.output_dir / "train_model.py"
        with open(script_path, 'w', encoding='utf-8') as f:
            f.write(script_content)

        print(f"âœ… è®­ç»ƒè„šæœ¬å·²åˆ›å»º: {script_path}")
        print(f"ğŸ’¡ è¿è¡Œè®­ç»ƒ: cd {self.output_dir} && python train_model.py")



def main():
    """ä¸»å‡½æ•° - å¯åŠ¨æ¸¸æˆå¹¶æˆªå›¾"""
    print("=" * 50)
    print("ğŸ® ä¸œæ–¹çº¢é­”ä¹¡ YOLOæ•°æ®ç”Ÿæˆå™¨")
    print("=" * 50)

    # åˆ›å»ºé¢„å¤„ç†å·¥ä½œæµ
    preprocessor = PreprocessingWorkflow()
    generator = YOLODataGenerator()

    # å¯åŠ¨æ¸¸æˆå¹¶æŸ¥æ‰¾çª—å£
    print("ğŸš€ å¯åŠ¨æ¸¸æˆ...")
    if not preprocessor.capture.start_game_and_find_window():
        print("âŒ æ¸¸æˆå¯åŠ¨å¤±è´¥æˆ–æœªæ‰¾åˆ°æ¸¸æˆçª—å£ï¼")
        print("è¯·æ£€æŸ¥æ¸¸æˆè·¯å¾„æ˜¯å¦æ­£ç¡®")
        return

    print("âœ… æ¸¸æˆå·²å¯åŠ¨ï¼Œçª—å£å·²æ‰¾åˆ°")
    print("ğŸ’¡ è¯·æ‰‹åŠ¨è¿›å…¥æ¸¸æˆç”»é¢ï¼ˆè·³è¿‡èœå•åˆ°å®é™…æ¸¸æˆä¸­ï¼‰")

    while True:
        print("\nè¯·é€‰æ‹©æ“ä½œ:")
        print("1. å¼€å§‹æˆªå›¾ (æŒ‰Ré”®æˆªå›¾ï¼ŒæŒ‰Qé”®ç»“æŸ)")
        print("2. å¤„ç†æˆªå›¾ç”Ÿæˆå¯è§†åŒ–")
        print("3. å°†ç­›é€‰å¥½çš„æ•°æ®è½¬æ¢ä¸ºYOLOè®­ç»ƒæ•°æ®")
        print("4. å®Œæ•´æµç¨‹ (å¤„ç†æˆªå›¾ + ç”ŸæˆYOLOæ•°æ®)")
        print("5. é€€å‡º")

        try:
            choice = input("\nè¯·è¾“å…¥é€‰æ‹© (1-5): ").strip()

            if choice == '1':
                print("\nğŸ® æˆªå›¾æ¨¡å¼å¯åŠ¨")
                print("æŒ‰ 'R' é”®æˆªå–æ¸¸æˆç”»é¢")
                print("æŒ‰ 'Q' é”®ç»“æŸæˆªå›¾")
                print("-" * 30)
                preprocessor.start_manual_capture()

            elif choice == '2':
                print("\nğŸ”„ å¼€å§‹å¤„ç†æˆªå›¾...")
                preprocessor.batch_process_images()
                print("\nâœ… é¢„å¤„ç†å®Œæˆï¼")
                print(f"å¯è§†åŒ–ç»“æœ: {preprocessor.visualizations_dir}")
                print("ğŸ’¡ è¯·æ£€æŸ¥å¯è§†åŒ–ç»“æœï¼Œç¡®è®¤æ•°æ®è´¨é‡åé€‰æ‹©é€‰é¡¹3è½¬æ¢ä¸ºYOLOæ ¼å¼")

            elif choice == '3':
                print("\nğŸ¯ æ ¹æ®å¯è§†åŒ–æ–‡ä»¶å¤¹è½¬æ¢YOLOè®­ç»ƒæ•°æ®...")
                print("ğŸ“‹ å·¥ä½œæµç¨‹:")
                print("   1. æ‰«æ preprocessing/visualizations/ æ–‡ä»¶å¤¹")
                print("   2. æ ¹æ®å‰©ä½™çš„å¯è§†åŒ–æ–‡ä»¶æ‰¾åˆ°å¯¹åº”çš„åŸå§‹æ•°æ®")
                print("   3. è½¬æ¢ä¸ºYOLOæ ¼å¼å¹¶ç§»åŠ¨åˆ°yoloæ–‡ä»¶å¤¹")
                print("   4. åˆ é™¤å·²è½¬æ¢çš„æ–‡ä»¶ï¼ˆä¿ç•™æ–‡ä»¶å¤¹ç»“æ„ï¼‰")
                print("âš ï¸ æ³¨æ„ï¼šè½¬æ¢åå°†åˆ é™¤å¯¹åº”çš„åŸå§‹æ–‡ä»¶ï¼")
                generator.convert_from_preprocessing()
                print("\nâœ… YOLOæ•°æ®è½¬æ¢å®Œæˆï¼")
                print(f"YOLOè®­ç»ƒæ•°æ®: {generator.output_dir}")
                print("ğŸ’¡ ç°åœ¨å¯ä»¥å¼€å§‹è®­ç»ƒYOLOæ¨¡å‹äº†")

            elif choice == '4':
                print("\nğŸ”„ å¼€å§‹å®Œæ•´æµç¨‹...")

                # æ‰¹é‡å¤„ç†å›¾åƒ
                preprocessor.batch_process_images()

                # è‡ªåŠ¨è½¬æ¢ä¸ºYOLOæ•°æ®
                print("\nğŸ¯ è½¬æ¢ä¸ºYOLOè®­ç»ƒæ•°æ®...")
                generator.convert_from_preprocessing()

                print("\nâœ… å®Œæ•´æµç¨‹å®Œæˆï¼")
                print(f"YOLOæ•°æ®ä¿å­˜åœ¨: {generator.output_dir}")
                print(f"é¢„å¤„ç†å¯è§†åŒ–: {preprocessor.visualizations_dir}")
                print(f"YOLOå¯è§†åŒ–: {generator.output_dir / 'visualizations'}")
                print("ğŸ’¡ å¯è§†åŒ–å›¾åƒæ˜¾ç¤ºäº†æ£€æµ‹ç‚¹å’Œå¯¹åº”çš„æ ‡æ³¨æ¡†")

            elif choice == '5':
                print("ğŸ‘‹ é€€å‡ºç¨‹åº")
                break

            else:
                print("âŒ æ— æ•ˆé€‰æ‹©ï¼è¯·è¾“å…¥ 1-5")

        except KeyboardInterrupt:
            print("\n\nâš ï¸ ç¨‹åºè¢«ä¸­æ–­")
            break
        except Exception as e:
            print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")

if __name__ == "__main__":
    main()
